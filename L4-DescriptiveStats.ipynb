{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lesson 4: Descriptive Statistics and Parameters\n",
    "\n",
    "**Python learning objectives**\n",
    "\n",
    "1. Learn how to combine two logic statements within a `.loc[]` function to coordinate data\n",
    "2. Practice mathematical functions on *DataFrame* columns.\n",
    "\n",
    "**What you will be able to do with these skills**\n",
    "\n",
    "1. Calculate the percentage change, variance and standard deviation from scratch.\n",
    "2. Learn how to describe a dataset with descriptive statistics and parameters\n",
    "3. Learn how to calculate the interquartile range and use it to find outliers within a dataset\n",
    "\n",
    "\n",
    "In this lesson you will learn how to calculate a range of different data descriptors, and even more importantly, you will learn how to interpret these measurements. \n",
    "\n",
    "Once again, in this lesson we need to import the `pandas` library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**Averages**\n",
    "\n",
    "The dataset used in this section is the number of days between British mine accidents with at least 10 fatalities between 06/12/1875 to 29/05/1951. [1]\n",
    "\n",
    "Below is a histogram plot of this dataset which shows its distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MineAccidentDF = pd.read_csv(\"https://raw.githubusercontent.com/ThomasJewson/datasets/master/TimeBetweenBritishMineAccident.csv\")\n",
    "MineAccidentDF.plot.hist(bins=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*1. Mean*\n",
    "\n",
    "The mean of a collection of numbers is the sum of all the elements of the collection, divided by the number of elements in the collection. \n",
    "\n",
    "The mean can be calculated with the `.mean()` [function](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.mean.html) which we use on our selected *DataFrame* column. In this case we want to find the mean of the `Time interval (days)` column in the `MineAccidentDF` *DataFrame*. Therefore, we use the following code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MineAccidentDF[\"Time interval (days)\"].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Properties of the Mean:\n",
    "\n",
    "- It does not need to be an element of the collection\n",
    "- It need not be an integer even if all the element of the collection are integers\n",
    "- It is between the largest and smallest elements within the collection\n",
    "- It is not necessarily halfway between the two extremes in the data. \n",
    "\n",
    "Note that the mean is not the \"halfway point\" of the data. If you look back at the histogram distribution you can prove this to yourself. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*2. Median*\n",
    "\n",
    "The median is the number that is in the middle of a sorted list of numbers. \n",
    "\n",
    "It can be calculated with `.median()` [function](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.median.html) used on a *DataFrame*.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MineAccidentDF[\"Time interval (days)\"].median()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the mean equals the median we have a symmetric distribution. If the mean does not equal the median then we have a skewed distribution. \n",
    "\n",
    "For example, below we produce and plot a symmettrical distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Symmetrical = pd.DataFrame(\n",
    "[1,2,2,3,3,3,4,4,4,4,5,5,5,5,5,6,6,6,6,7,7,7,8,8,9]\n",
    ")\n",
    "Symmetrical.plot.hist(bins=9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MyDataFrame.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Symmetrical[0].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Symmetrical[0].median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Symmetrical[0].median() == Symmetrical[0].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the median and the mean are equal, this distribution is symmetrical. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Excercise 1:** *Produce a logic expression and get either a `True` or `False` result by equating - with the `==` operator - the mean and median of `MineAccidentDF[\"Time interval (days)\"]`, just like the above cell. What does the result of this expression tell us about the symmetry of the distribution?*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Answer\n",
    "MineAccidentDF[\"Time interval (days)\"].median() == MineAccidentDF[\"Time interval (days)\"].mean()\n",
    "\n",
    "#False - Therefore unsymmetrical distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*3. Mode*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The mode, or the modal value, is the most common datum in a set. \n",
    "\n",
    "It can be calculated with `.mode()` [function](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.mode.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Symmetrical[0].mode()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Measures of spread**\n",
    "\n",
    "*1. Variability and Variance*\n",
    "\n",
    "A simple method to measure the variability is to measure the deviation from the mean. This can be achieved by subtracting the mean from the data.\n",
    "\n",
    "$ Mean \\space Deviation = Data - Mean $\n",
    "\n",
    "The code below does the following:\n",
    "\n",
    "1. Calculates the mean of the `Symmetrical` *DataFrame* with the `.mean()` function and saves the result in a variable called `SymmetircalMean`.\n",
    "```Python\n",
    "SymmetricalMean = Symmetrical.mean()\n",
    "```\n",
    "2. Calculates the mean deviation by subtracting the mean from the data and saves it as a new column in `Symmetrical` called `\"Deviation from Mean\"`. \n",
    "```Python\n",
    "Symmetrical[\"Deviation from Mean\"] = Symmetrical - SymmetricalMean\n",
    "```\n",
    "3. Then the `Symmetrical` *DataFrame* is outputted by calling its name.\n",
    "```Python\n",
    "Symmetrical\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SymmetricalMean = Symmetrical.mean() # Finds the mean of our dataset\n",
    "Symmetrical[\"Deviation from Mean\"] = Symmetrical - SymmetricalMean # Finds the mean deviation of each piece of data\n",
    "Symmetrical # outputs the DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The deviations are negative when the data is less than the mean and positive when the data is greater than the mean. \n",
    "\n",
    "These deviations from the mean can give us an idea about the spread or variability of the data. However, it doesnt give us a single figure to use to describe the data as a whole. \n",
    "\n",
    "To find a single figure to describe the data you might want to find the average of these deviations - however, we do not get a useful answer..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Symmetrical[\"Deviation from Mean\"].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The mean value of the deviations from the mean is always equal to zero. This is because the negative and positive values cancel each other."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The mean of the deviations is, therefore, not a useful measure of the variability of the sample. We want to find the variability regardless of whether the deviation away from the mean is positive or negative. So we need to eliminate the signs in the deviations. \n",
    "\n",
    "This can be done either with squaring or via finding the absolute. We are going to do it via the squaring method.\n",
    "\n",
    "The code below squares the `Deviations from Mean` column and saves the data in a new column in the `Symmetrical` *DataFrame* called `Squared Deviation`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Symmetrical[\"Squared Deviation\"] = Symmetrical[\"Deviation from Mean\"] ** 2\n",
    "Symmetrical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now if we take the mean of `Symmetical[\"Squared Deviation\"]` we will have the *mean squared deviation* - otherwise known as the *population variance*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Symmetrical[\"Squared Deviation\"].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The overall process of this calculation can be represented with the following equation.\n",
    "\n",
    "\n",
    "${\\large \\text{Population Variance}=\\sigma^2=\\frac{1}{N}\\sum_{i=1}^{N}(x_{i}-\\overline{x})^2}$\n",
    "\n",
    "\n",
    "\n",
    "$\\overline{x} = \\text{Mean}$\n",
    "\n",
    "$N = \\text{Population}$\n",
    "\n",
    "$x_{i} = \\text{Each piece of data}$\n",
    "\n",
    "\n",
    "\n",
    "$(x_{i}-\\overline{x})^2 = \\text{Squared deviation from the mean}$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can compare this *population variance* that we have calculated to the *sample variance* which can be calculated with the `.var()` [function](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.var.html). \n",
    "\n",
    "The *sample variance* is always greater than the *population variance*. This is because in the *sample variance* we divide by the smaller $n-1$, whereas, in the *population variance* we divide by greater $N$. \n",
    "\n",
    "${\\large \\text{Sample Variance}=s^2=\\frac{1}{n-1}\\sum_{i=1}^{n}(x_{i}-\\overline{x})^2}$\n",
    "\n",
    "$n = \\text{Sample population}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Symmetrical[0].var() # Sample Variance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Excercise 2:** *Calculate the variance of `MineAccidentDF[\"Time interval (days)\"]`*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#answer\n",
    "MineAccidentDF[\"Time interval (days)\"].var()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*2. Standard Deviation*\n",
    "\n",
    "The problem with variance is that it is not on the same scale as the original variable because we have squared it. However, if we take the positive square root of the variance it leads to a parameter that is on the same scale as our initial dataset and as a consequence it is more comparable. This is the *standard deviation*.\n",
    "\n",
    "The *standard deviation* is the root mean squared deviation from the mean value. \n",
    "\n",
    "We can calculate the square root by powering our value by a half (`** 0.5`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variance = Symmetrical[\"Squared Deviation\"].mean()\n",
    "standarddeviation = variance ** 0.5 \n",
    "\n",
    "standarddeviation # Population Standard Deviation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This results is the *population standard deviation*. \n",
    "\n",
    "$\\large\\text{Population Standard Deviation}=\\sigma^2=\\sqrt{\\frac{1}{N}\\sum_{i=1}^{N}(x_{i}-\\overline{x})^2}$\n",
    "\n",
    "Again, we can calculate the slightly greater *sample population* with the `.std()` [function](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.std.html). \n",
    "\n",
    "$\\large\\text{Sample Standard Deviation}=s^2=\\sqrt{\\frac{1}{n-1}\\sum_{i=1}^{n}(x_{i}-\\overline{x})^2}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Symmetrical[0].std() # Sample Standard Deviation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Excercise 3:** *Calculate the standard deviation of `MineAccidentDF[\"Time interval (days)\"]`*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#answer\n",
    "MineAccidentDF[\"Time interval (days)\"].std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*3. Interquartile Range*\n",
    "\n",
    "The standard deviation suffers from being sensitive to outliers. If we look at the distribution of the British mine accidents again (below) you will notice the vast majority of the data is to the left hand side of the histogram. Therefore, our standard deviation might be skewed the few outliers that lie to the far right hand side of the distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MineAccidentDF.plot.hist(bins=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we use a measurement of spread that is less sensitive to outliers, we might end up with a more accurate description of our data. The *interquartile range* (*IQR*) is exactly that due to it being robust to outliers. It is robust as the outliers are not directly used within the calculation of the parameter. Whereas, the *standard deviation*, *variance* and *mean* use *all* the data in the calculation - including the outliers - therefore they are sensitive to outliers. \n",
    "\n",
    "If we were to organise the data from least to greatest and then we split the data at the median we would have an upper and lower half of the data. Then if we found the medians of both these upper and lower halfs of data and found the difference between them, this would be the *IQR*. \n",
    "\n",
    "The word 'quartile' comes from the idea that we are seperating the data into four segments. Each of these segments gives us our quartile statistic. \n",
    "\n",
    "The first quartile ($Q1$) is the median of the lower half of the data - or exactly 25% through the list of the organised data. \n",
    "\n",
    "The median of the total population is the second quartile ($Q2$) - 50% through the list of organised data.\n",
    "\n",
    "The third quartile ($Q3$) is the median of the upper half of the data - 75% through the list of organised data.\n",
    "\n",
    "Finally, the fourth quartile ($Q4$) - which isn't of much use - is the very last piece of data in the organised list. \n",
    "\n",
    "We calculate the *IQR* with the following:\n",
    "\n",
    "$\\large IQR = Q3 - Q1$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To find the quartiles we use the `.quantile()` [function](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.quantile.html) on our *DataFrame* (Note the function is **quant**ile rather than **quart**ile).\n",
    "\n",
    "As $Q2$ is 25% through the list of organised data we need to have `0.25` as a parameter in the function. Likewise, $Q3$ needs to have `0.75` as a parameter as it is 75% through the data. As this argument is a number we do not need to surround it in `\"\"`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q1 = MineAccidentDF[\"Time interval (days)\"].quantile(0.25)\n",
    "Q1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q3 = MineAccidentDF[\"Time interval (days)\"].quantile(0.75)\n",
    "Q3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With these statistics we can work out the IQR with the formula above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IQR = Q3 - Q1\n",
    "IQR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Excercise 4:** *Calculate Q1 with `.quantile(0.25)` and Q3 with `.quantile(0.75)` of the `Symmetrical[0]` DataFrame printing the results.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Answer\n",
    "print(Symmetrical[0].quantile(0.25))\n",
    "print(Symmetrical[0].quantile(0.75))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Box plots and Outliers**\n",
    "\n",
    "Several statistical parameters are particularly sensitive to outliers, in particular the *mean*, *variance* and the *standard deviation*. To minimise these parameters being skewed it is common to remove outliers in datasets. \n",
    "\n",
    "There are several ways to calculate what an outlier is, we are going to be using the $1.5 \\cdot IQR$ method. \n",
    "\n",
    "With this method we create bounds where the vast majority of the data resides. We expand $Q1$ and $Q3$ by $1.5 \\cdot IQR$ on both sides. The bounds are calculated with the formulas below.\n",
    "\n",
    "$LowerBound = Q1 - 1.5*IQR$ \n",
    "\n",
    "$UpperBound = Q3 + 1.5*IQR$\n",
    "\n",
    "The data which is greater than the *lower bound* and smaller than the *upper bound* is the data we keep. Therefore, if a piece of data is outside of these bounds we class it as an outlier and we drop it from our dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LowerBound = Q1 - 1.5*IQR\n",
    "LowerBound"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HigherBound = Q3 + 1.5*IQR\n",
    "HigherBound"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To remove outliers from a *DataFrame* we firstly need to form a logic statement that describes the data we want to keep. This can be done in the following way:\n",
    "\n",
    "1. We want all the data from `MineAccidentDF[\"Time interval (days)\"]` less than the `HigherBound`. This can be described with the following.\n",
    "    ```Python\n",
    "    MineAccidentDF[\"Time interval (days)\"] < HigherBound\n",
    "    ```\n",
    "2. And we want all the data from `MineAccidentDF[\"Time interval (days)\"]` greater than the `LowerBound`. This can be described with the following.\n",
    "    ```Python\n",
    "    MineAccidentDF[\"Time interval (days)\"] > LowerBound\n",
    "    ```\n",
    "3. We can combine both of these logic statements by using the `&` symbol. Note, we need to use brackets around each of the conjoining statements.\n",
    "    ```Python\n",
    "    (MineAccidentDF[\"Time interval (days)\"] < HigherBound) & (MineAccidentDF[\"Time interval (days)\"] > LowerBound)\n",
    "    ```\n",
    "    Unfortunately we cannot use the following statement ` LowerBound < MineAccidentDF[\"Time interval (days)\"] < HigherBound` in Python, and we need to use the `&` symbol instead.\n",
    "    \n",
    "    \n",
    "Below is an example of the conjoined statement. All the `True` results is the data we keep, and `False` are the outliers which will be excluded later on. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(MineAccidentDF[\"Time interval (days)\"] < HigherBound) & (MineAccidentDF[\"Time interval (days)\"] > LowerBound)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To exclude all the outliers, we simply need to place the conjoined logic statement into a `.loc[]` function which operates on our `MineAccidentDF`. \n",
    "\n",
    "The code below does just that, and saves the resultant *DataFrame* as `MineAccident_ExOutliers`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MineAccident_ExOutliers = MineAccidentDF.loc[(MineAccidentDF[\"Time interval (days)\"] < HigherBound) & (MineAccidentDF[\"Time interval (days)\"] > LowerBound)]\n",
    "MineAccident_ExOutliers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Therefore, we now how a new DataFrame, `MineAccident_ExOutliers`, which has removed all the outliers as defined by our bounds.\n",
    "\n",
    "Plotting `MineAccident_ExOutliers` in a histogram will demonstrate how the distribution has changed as a consequence. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MineAccident_ExOutliers.plot.hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we compare the mean averages of our *DataFrame* before and after removing outliers it will also demonstrate how sensitive the mean is to outliers. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MineAccident_ExOutliers[\"Time interval (days)\"].mean()  # Excluding Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MineAccidentDF[\"Time interval (days)\"].mean()  # Including Outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Box plots - or box-and-whisker plots - are another way to plot the distribution of data. In particular, this plot uses the $1.5*IQR$ outlier method to find outliers. This plot is a very quick way to assess a dataset to find any particular outliers.\n",
    "\n",
    "To plot a box plot we need to use the `.plot.box()` [function](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.plot.box.html). We do not need to pass any arguments in this function.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MineAccidentDF.plot.box()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The central orange line is the median of the *DataFrame*.\n",
    "\n",
    "The blue box surrounding the median (orange line) is $Q1$ and $Q3$.\n",
    "\n",
    "The whiskers on this blue box depict $1.5 * IQR$ away from $Q1$ and $Q3$. \n",
    "\n",
    "Individual pieces of data outside of the whiskers are outliers and are depicted with circles."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Excercise 5:** *Draw a box plot of `Symmetrical[0]`.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#answer\n",
    "Symmetrical[0].plot.box()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Percentage Change and Growth Rates**\n",
    "\n",
    "Below is data from Covid-19 outbreak in the EU between 01/01/2020 to 30/06/2020. [2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "covid_df = pd.read_csv(\"https://raw.githubusercontent.com/ThomasJewson/datasets/master/EUCOVID19CasesDeaths.csv\")\n",
    "covid_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Jan there were 17 confirmed cases in the EU of Covid-19, by Feb there was 1126 cases. To compute the percentage change between these two we need to use the following:\n",
    "\n",
    "$\\large \\text{Percentage Change}=100*\\frac{Final - Initial}{Initial}$\n",
    "\n",
    "Alternatively we can also use this equation: \n",
    "\n",
    "$\\large \\text{Percentage Change}=100*\\frac{Final}{Initial}-1$\n",
    "\n",
    "We calculate the percentage change between Jan and Feb in the code below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial = 17\n",
    "final = 1126\n",
    "pctchange = 100*(final - initial) / initial\n",
    "pctchange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pctchange = 100*((final / initial) - 1)\n",
    "pctchange"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see there was a very large percentage increase in COVID-19 cases in the EU between Jan and Feb. \n",
    "\n",
    "Generally, percentage changes are not whole numbers so it is useful for us to round the result. This can be done with the `round()` [function](https://docs.python.org/3/library/functions.html#round).\n",
    "\n",
    "The round function requires two positional arguments. The first argument is the data we want to round, in this case it is the `pctchange` variable. The second argument is the number of decimal places we want to round to, which we express as an integer. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "round(\n",
    "    pctchange, #This is our data\n",
    "    1 #This is the number of decimal places to round to\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To calculate the percentage change for a whole column of data in a DataFrame we use the `.pct_change()` [function](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.pct_change.html). However, we still need to multiply by 100 to turn it into a percentage. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pctdata = covid_df[\"Confirmed Cases\"].pct_change()*100\n",
    "pctdata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also round all the numbers in a *DataFrame* with the `round()` [function](https://docs.python.org/3/library/functions.html#round) by placing our `pctdata` *DataFrame* as the first argument of the function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "round(pctdata,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From this we can tell that the coronavirus was increasing through the EU at the fastest rate in March 2020 as it had a percentage increase in cases of 38,043.43%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conclusions:**\n",
    "\n",
    "*You should now be able to do the following:*\n",
    "\n",
    "1. Calculate the following averages:\n",
    "    1. Mean with `.mean()`\n",
    "    2. Median with `.median()`\n",
    "    3. Mode with `.mode()`\n",
    "2. Calculate the following measures of spread:\n",
    "    1. Variance from scratch and with `.var()`\n",
    "    2. Standard deviation from scratch and with `.std()`\n",
    "3. Calculate the interquartile range (IQR) with the use of the `.quantile` function\n",
    "4. Use the ${1.5*IQR}$ method to remove outliers by using `&` between two logic statements\n",
    "5. Produce a box plot with `.plot.box()`.\n",
    "6. Find the percentage change manually and also with the `.pct_change()` function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Sources:**\n",
    "\n",
    "[1] B.A. Maguire, E.S. Pearson, A.H.A. Wynn (1952).\n",
    "\"The Time Intervals Between Industrial Accidents\", Biometrika Vol. 39, #1/2 pp. 168-180\n",
    "\n",
    "[2] European Centre for Disease Prevention and Control"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
